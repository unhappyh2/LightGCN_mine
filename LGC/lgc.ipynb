{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-19T06:49:50.197777Z",
     "start_time": "2024-11-19T06:49:50.185429Z"
    }
   },
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    " \n",
    "from torch_sparse import SparseTensor, matmul\n",
    " \n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:49:50.213824Z",
     "start_time": "2024-11-19T06:49:50.203704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movie_path = '../data/ml-20m/movies.csv'\n",
    "rating_path = '../data/ml-20m/ratings.csv'"
   ],
   "id": "1360dc9bfc474216",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:49:50.244339Z",
     "start_time": "2024-11-19T06:49:50.236342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_node_csv(path, index_col):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path (str): 数据集路径\n",
    "        index_col (str): 数据集文件里的列索引\n",
    "    Returns:\n",
    "        dict: 列号和用户ID的索引、列好和电影ID的索引\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, index_col=index_col)\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}  # enumerate()索引函数,默认索引从0开始\n",
    "    return mapping\n"
   ],
   "id": "ea548c0aaa6b6080",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:49:56.349063Z",
     "start_time": "2024-11-19T06:49:50.248476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_mapping = load_node_csv(rating_path, index_col='userId')\n",
    "movie_mapping = load_node_csv(movie_path, index_col='movieId')"
   ],
   "id": "61bbb9bb05fc4a85",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:49:56.365064Z",
     "start_time": "2024-11-19T06:49:56.352066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path (str): 数据集路径\n",
    "        src_index_col (str): 用户列名\n",
    "        src_mapping (dict): 行号和用户ID的映射\n",
    "        dst_index_col (str): 电影列名\n",
    "        dst_mapping (dict): 行号和电影ID的映射\n",
    "        link_index_col (str): 交互的列名\n",
    "        rating_threshold (int, optional): 决定选取多少评分交互的阈值，设置为4分\n",
    "    Returns:\n",
    "        torch.Tensor: 2*N的用户电影交互节点图\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    edge_index = None\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold  # 将数组转化为tensor张量\n",
    "    edge_index = [[], []]\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i]:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    " \n",
    "    return torch.tensor(edge_index)\n"
   ],
   "id": "2e9634b2eb8247f6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:23.994250Z",
     "start_time": "2024-11-19T06:49:56.367064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "edge_index = load_edge_csv(\n",
    "    rating_path,\n",
    "    src_index_col='userId',\n",
    "    src_mapping=user_mapping,\n",
    "    dst_index_col='movieId',\n",
    "    dst_mapping=movie_mapping,\n",
    "    link_index_col='rating',\n",
    "    rating_threshold=4,\n",
    ")\n"
   ],
   "id": "78a2ecd174c82448",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.025234Z",
     "start_time": "2024-11-19T06:51:23.997244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
    "num_interactions = edge_index.shape[1]\n",
    "all_indices = [i for i in range(num_interactions)]  # 所有索引\n",
    " \n",
    "train_indices, test_indices = train_test_split(\n",
    "    all_indices, test_size=0.2, random_state=1)  # 将数据集划分成80:10的训练集:测试集\n",
    "val_indices, test_indices = train_test_split(\n",
    "    test_indices, test_size=0.5, random_state=1)  # 将测试集划分成10:10的验证集:测试集,最后的比例就是80:10:10\n",
    " \n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]\n",
    "\n",
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1])\n",
    "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1])\n"
   ],
   "id": "a6406dd4d8a1ff06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T11:46:44.491934Z",
     "start_time": "2024-11-19T11:46:43.567024Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_edge_index.shape)",
   "id": "22a652d6f35c06bd",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_edge_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtrain_edge_index\u001B[49m\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_edge_index' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.041512Z",
     "start_time": "2024-11-19T06:51:35.027237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        batch_size (int): 批大小\n",
    "        edge_index (torch.Tensor): 2*N的边列表\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    indices = random.choices(\n",
    "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    batch = edges[:, indices]\n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices\n"
   ],
   "id": "28c02e90da824683",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.584533Z",
     "start_time": "2024-11-19T06:51:35.044034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class LightGCN(MessagePassing):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_users (int): 用户数量\n",
    "            num_items (int): 电影数量\n",
    "            embedding_dim (int, optional): 嵌入维度，设置为64，后续可以调整观察效果\n",
    "            K (int, optional): 传递层数，设置为3，后续可以调整观察效果\n",
    "            add_self_loops (bool, optional): 传递时加不加自身节点，设置为不加\n",
    "        \"\"\"\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    " \n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim)  # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim)  # e_i^0\n",
    " \n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)  # 从给定均值和标准差的正态分布N(mean, std)中生成值，填充输入的张量或变量\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    " \n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            edge_index (SparseTensor): 邻接矩阵\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u%^k, e_u^0, e_i^k, e_i^0\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    " \n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    " \n",
    "        # 多尺度扩散\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "            embs.append(emb_k)\n",
    " \n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1)  # E^K\n",
    " \n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items])  # splits into e_u^K and e_i^K\n",
    " \n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    " \n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    " \n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        # computes \\tilde{A} @ x\n",
    "        return matmul(adj_t, x)\n"
   ],
   "id": "7ede102e6fe72c8a",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.738848Z",
     "start_time": "2024-11-19T06:51:35.586450Z"
    }
   },
   "cell_type": "code",
   "source": "model = LightGCN(num_users, num_movies)",
   "id": "f17da3323af74fd1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.754291Z",
     "start_time": "2024-11-19T06:51:35.740778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u^k\n",
    "        users_emb_0 (torch.Tensor): e_u^0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i^k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i^0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i^k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i^0\n",
    "        lambda_val (float): λ的值\n",
    "    Returns:\n",
    "        torch.Tensor: loss值\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2))  # L2 loss L2范数是指向量各元素的平方和然后求平方根\n",
    " \n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # 正采样预测分数\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # 负采样预测分数\n",
    " \n",
    "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
    " \n",
    "    return loss\n"
   ],
   "id": "fa504203e87b213b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.770337Z",
     "start_time": "2024-11-19T06:51:35.755813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"为每个用户生成正采样字典\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2*N的边列表\n",
    "    Returns:\n",
    "        dict: 每个用户的正采样字典\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items\n"
   ],
   "id": "d8e0cc5a8075a564",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.785724Z",
     "start_time": "2024-11-19T06:51:35.774342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        groundTruth (list): 每个用户对应电影列表的高评分项\n",
    "        r (list): 是否向每个用户推荐了前k个电影的列表\n",
    "        k (intg): 确定要计算精度和召回率的前k个电影\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
    "                                  for i in range(len(groundTruth))])\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()\n"
   ],
   "id": "9b2ed1530aee9eac",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.800787Z",
     "start_time": "2024-11-19T06:51:35.787231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "    Args:\n",
    "        groundTruth (list): 同上一个函数\n",
    "        r (list): 同上一个函数\n",
    "        k (int): 同上一个函数\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    " \n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    " \n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()\n"
   ],
   "id": "2f3ebbe4b46b197d",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.816306Z",
     "start_time": "2024-11-19T06:51:35.803781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2*N列表\n",
    "        exclude_edge_indices ([type]): 2*N列表\n",
    "        k (int): 前多少个电影\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    " \n",
    "    # get ratings between every user and item - shape is num users x num movies\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    " \n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    " \n",
    "        # set ratings of excluded edges to large negative value\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    " \n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    " \n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    " \n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    " \n",
    "    # convert test user pos items dictionary into a list\n",
    "    test_user_pos_items_list = [\n",
    "        test_user_pos_items[user.item()] for user in users]\n",
    " \n",
    "    # determine the correctness of topk predictions\n",
    "    r = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    " \n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    " \n",
    "    return recall, precision, ndcg\n"
   ],
   "id": "b478094062ff74a2",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.831949Z",
     "start_time": "2024-11-19T06:51:35.819305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
    "    # get embeddings\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        sparse_edge_index)\n",
    "    edges = structured_negative_sampling(\n",
    "        edge_index, contains_neg_self_loops=False)\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    " \n",
    "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
    "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
    " \n",
    "    recall, precision, ndcg = get_metrics(\n",
    "        model, edge_index, exclude_edge_indices, k)\n",
    " \n",
    "    return loss, recall, precision, ndcg\n"
   ],
   "id": "1cc718331c85fd1b",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.847260Z",
     "start_time": "2024-11-19T06:51:35.833948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6"
   ],
   "id": "a16bf60a567da4d4",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:35.863160Z",
     "start_time": "2024-11-19T06:51:35.848259Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "ed216158cf58191e",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:36.189104Z",
     "start_time": "2024-11-19T06:51:35.864677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = model.to(device)\n",
    "model.train()\n",
    " \n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    " \n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    " \n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = val_sparse_edge_index.to(device)\n"
   ],
   "id": "47b3899fc9b71805",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:36.825048Z",
     "start_time": "2024-11-19T06:51:36.191108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    " \n",
    "for iter in range(ITERATIONS):\n",
    "    # forward propagation\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        train_sparse_edge_index)\n",
    " \n",
    "    # mini batching\n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
    "        BATCH_SIZE, train_edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    " \n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
    "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    " \n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    " \n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()\n"
   ],
   "id": "b8cf6008161e84d7",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m val_losses \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(ITERATIONS):\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# forward propagation\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m     users_emb_final, users_emb_0, items_emb_final, items_emb_0 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_sparse_edge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# mini batching\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     user_indices, pos_item_indices, neg_item_indices \u001B[38;5;241m=\u001B[39m sample_mini_batch(\n\u001B[0;32m     11\u001B[0m         BATCH_SIZE, train_edge_index)\n",
      "Cell \u001B[1;32mIn[30], line 33\u001B[0m, in \u001B[0;36mLightGCN.forward\u001B[1;34m(self, edge_index)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;124;03m    edge_index (SparseTensor): 邻接矩阵\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03m    tuple (Tensor): e_u%^k, e_u^0, e_i^k, e_i^0\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# compute \\tilde{A}: symmetrically normalized adjacency matrix\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m edge_index_norm \u001B[38;5;241m=\u001B[39m \u001B[43mgcn_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m    \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_self_loops\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_self_loops\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m emb_0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39musers_emb\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems_emb\u001B[38;5;241m.\u001B[39mweight]) \u001B[38;5;66;03m# E^0\u001B[39;00m\n\u001B[0;32m     37\u001B[0m embs \u001B[38;5;241m=\u001B[39m [emb_0]\n",
      "File \u001B[1;32m~\\.conda\\envs\\myproject_pytorch\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:57\u001B[0m, in \u001B[0;36mgcn_norm\u001B[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001B[0m\n\u001B[0;32m     54\u001B[0m fill_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2.\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m improved \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1.\u001B[39m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(edge_index, SparseTensor):\n\u001B[1;32m---> 57\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m edge_index\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m==\u001B[39m edge_index\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     59\u001B[0m     adj_t \u001B[38;5;241m=\u001B[39m edge_index\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m adj_t\u001B[38;5;241m.\u001B[39mhas_value():\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T06:51:36.828053Z",
     "start_time": "2024-11-19T06:51:36.827046Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "16fb574f57ddff29",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
